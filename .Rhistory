par(mar=c(0.5,0.5,1,1))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="uncertain model parameter", ylab="policy performance")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.08)
policy2=dnorm(x, mean=0.5, sd=.15)+1.5
par(mar=c(2,2,2,,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="uncertain model parameter", ylab="policy performance")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="uncertain model parameter", ylab="policy performance")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter")
mtext(side=1, text="uncertain model parameter"m line=1)
mtext(side=1, text="uncertain model parameter"m line=1)
mtext(side=1, text="uncertain model parameter"m line=1.5)
mtext(side=1, text="uncertain model parameter", line=1.5)
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=1, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.08)
policy2=dnorm(x, mean=0.5, sd=.15)+1.5
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.08)
policy2=dnorm(x, mean=0.5, sd=.2)+1.5
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.05)
policy2=dnorm(x, mean=0.5, sd=.2)+1.5
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.05)
policy2=dnorm(x, mean=0.5, sd=.2)+3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.05)
policy2=dnorm(x, mean=0.5, sd=.2)+3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.05)
policy2=dnorm(x, mean=0.5, sd=.2)+3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="policy performance", line=.5)
x=seq(8, 25, 0.01)
policy1=x^4-3*x^2
x=seq(8, 25, 0.01)
policy1=x^4-3*x^2
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
x=seq(8, 25, 0.01)
policy1=x^4-3*x^3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
x=seq(8, 25, 0.01)
policy1=x^4-100*x^3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
x=seq(-100, 100, 1)
policy1=x^4-100*x^3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
x=seq(0,1, 0.005)
policy1=dnorm(x, mean = 0.5, sd=.05)
policy2=dnorm(x, mean=0.5, sd=.2)+3
par(mar=c(2,2,2,2))
plot(x=x, y=(policy1), type="l", col='black', lwd=2, yaxt="n", xaxt="n", xlab="", ylab="")
lines(x=x, y=(policy2), col="lightgray", lwd=2)
legend("topright", legend=c("policy 1", "policy 2"), col=c("black", "lightgray"), lwd=c(2,2), bty="n")
mtext(side=1, text="uncertain model parameter", line=.5)
mtext(side=2, text="maximization objective", line=.5)
library(reticulate)
use_virtualenv("venv")
import("ema_workbench")
library(dplyr)
### load stress testing data from robustness runs
obj_all=read.table('objectives_all463.txt') # load data for calculating robustness
obj_all=rename(obj_all, "ID"="policy")
vol_index=which(colnames(obj_all) %in% c('LB.Shortage.Volume',"LB.Shortage.Volume.Policy", "Max.Annual.LB.Shortage"))
obj_all[,vol_index]=obj_all[,vol_index]/1000 # convert to KAF
obj_all[["Powell.WY.Release"]]=obj_all[["Powell.WY.Release"]]/(10^6) # convert to MAF
### load uncertainty metrics
SOW_500_300_100=readRDS("SOW ensemble 500_300_100.rds") # list of SOW ensembles, for sensitivity analysis of 300 vs 500 ensemble
SOW_id=sort(SOW_500_300_100[[2]]$model) # SOW IDs of the 300 member SOW ensemble
policyID=300
obj.filter=dplyr::filter(obj_all, ID %in% policyID)
ensembleInput="cLHS 500"
if (ensembleInput == "cLHS 300"){ensemble=SOW_500_300_100[[2]]$SOW} else {ensemble=SOW_500_300_100[[1]]$SOW}
x=ensemble[, -c(4,5)] # remove Hydro Scenario and trace number
objSelect="Mead.1000"
threshSelect=10
y=obj.filter[[objSelect]] > threshSelect # define cases of interest, ie vulnerable
objSelect="Mead.1000"
threshSelect=10
y=obj.filter[[objSelect]] > threshSelect # define cases of interest, ie vulnerable
library(reticulate)
use_virtualenv("venv")
import("ema_workbench")
knitr::knit_engines$set(python=reticulate::eng_python)
library(dplyr)
### load stress testing data from robustness runs
obj_all=read.table('objectives_all463.txt') # load data for calculating robustness
obj_all=rename(obj_all, "ID"="policy")
vol_index=which(colnames(obj_all) %in% c('LB.Shortage.Volume',"LB.Shortage.Volume.Policy", "Max.Annual.LB.Shortage"))
obj_all[,vol_index]=obj_all[,vol_index]/1000 # convert to KAF
obj_all[["Powell.WY.Release"]]=obj_all[["Powell.WY.Release"]]/(10^6) # convert to MAF
### load uncertainty metrics
SOW_500_300_100=readRDS("SOW ensemble 500_300_100.rds") # list of SOW ensembles, for sensitivity analysis of 300 vs 500 ensemble
SOW_id=sort(SOW_500_300_100[[2]]$model) # SOW IDs of the 300 member SOW ensemble
x_py=r_to_py(x, convert=T)
y_py=r_to_py(y, convert=T)
py$x=x
py$y=y
py$x
library(reticulate)
use_virtualenv("venv")
import("ema_workbench")
library(dplyr)
### load stress testing data from robustness runs
obj_all=read.table('objectives_all463.txt') # load data for calculating robustness
obj_all=rename(obj_all, "ID"="policy")
vol_index=which(colnames(obj_all) %in% c('LB.Shortage.Volume',"LB.Shortage.Volume.Policy", "Max.Annual.LB.Shortage"))
obj_all[,vol_index]=obj_all[,vol_index]/1000 # convert to KAF
obj_all[["Powell.WY.Release"]]=obj_all[["Powell.WY.Release"]]/(10^6) # convert to MAF
### load uncertainty metrics
SOW_500_300_100=readRDS("SOW ensemble 500_300_100.rds") # list of SOW ensembles, for sensitivity analysis of 300 vs 500 ensemble
SOW_id=sort(SOW_500_300_100[[2]]$model) # SOW IDs of the 300 member SOW ensemble
policyID=300
obj.filter=dplyr::filter(obj_all, ID %in% policyID)
ensembleInput="cLHS 500"
if (ensembleInput == "cLHS 300"){ensemble=SOW_500_300_100[[2]]$SOW} else {ensemble=SOW_500_300_100[[1]]$SOW}
x=ensemble[, -c(4,5)] # remove Hydro Scenario and trace number
py$x=x
objSelect="Mead.1000"
threshSelect=10
y=obj.filter[[objSelect]] > threshSelect # define cases of interest, ie vulnerable
py$y=y
View(py)
x=r_to_py(x)
y=r_to_py(y)
update.packages("knitr")
```{r, setup}
library(reticulate)
py$x
library(reticulate)
py$x
use_condaenv()
py$x
py$y <- head(cars)
reticulate::py_config()
packageVersion("rmarkdown")
packageVersion("knitr")
library(reticulate)
py$x
py$y <- head(cars)
library(reticulate)
library(reticulate)
use_condaenv()
repl_python(
print(y)
)
py_run_string(
print(y)
)
py$y <- head(cars)
py_run_string(
print(py.y)
)
py_available()
py_run_string(
"print(y)"
)
py_run_string(
"print(py.y)"
)
y=head(cars)
py_run_string(
"print(r.y)"
)
py_run_string(
"print(r.y)
x=10"
)
py_run_string(
"print(r.y); x=10"
)
py$x
py_run_string(
"x=10"
)
py$x
py_run_string(
"x=10"
)
py$x
py_run_string(
"x = 10"
)
py$x
py_run_string(
"x = 10"
);py$x
py$x
library(reticulate)
use_virtualenv("venv")
import("ema_workbench")
library(dplyr)
### load stress testing data from robustness runs
obj_all=read.table('objectives_all463.txt') # load data for calculating robustness
obj_all=rename(obj_all, "ID"="policy")
vol_index=which(colnames(obj_all) %in% c('LB.Shortage.Volume',"LB.Shortage.Volume.Policy", "Max.Annual.LB.Shortage"))
obj_all[,vol_index]=obj_all[,vol_index]/1000 # convert to KAF
obj_all[["Powell.WY.Release"]]=obj_all[["Powell.WY.Release"]]/(10^6) # convert to MAF
### load uncertainty metrics
SOW_500_300_100=readRDS("SOW ensemble 500_300_100.rds") # list of SOW ensembles, for sensitivity analysis of 300 vs 500 ensemble
SOW_id=sort(SOW_500_300_100[[2]]$model) # SOW IDs of the 300 member SOW ensemble
policyID=300
obj.filter=dplyr::filter(obj_all, ID %in% policyID)
ensembleInput="cLHS 500"
if (ensembleInput == "cLHS 300"){ensemble=SOW_500_300_100[[2]]$SOW} else {ensemble=SOW_500_300_100[[1]]$SOW}
x=ensemble[, -c(4,5)] # remove Hydro Scenario and trace number
objSelect="Mead.1000"
threshSelect=10
y=obj.filter[[objSelect]] > threshSelect # define cases of interest, ie vulnerable
py_run_string(
"rom ema_workbench.analysis import (prim, feature_scoring)
peel=prim.Prim(r.x,r.y, threshold=.7)
Mead_norm_PRIM=peel.find_box()"
)
py_run_string(
"from ema_workbench.analysis import (prim, feature_scoring)
peel=prim.Prim(r.x,r.y, threshold=.7)
Mead_norm_PRIM=peel.find_box()"
)
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("peel=prim.Prim(r.x,r.y, threshold=.7)")
py_run_string("peel=prim.Prim(r.x,r.y, threshold=.7)")
py_run_string("x=r.x")
py_run_string("y=r.y")
py_run_string("peel=prim.Prim(x,y, threshold=.7)")
import("pandas")
py_run_string("x=pandas.DataFrame(r.x)")
py_run_string("x=pd.DataFrame(r.x)")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=pd.DataFrame(r.x)")
library(reticulate)
use_virtualenv("venv")
import("ema_workbench")
import("pandas")
library(dplyr)
### load stress testing data from robustness runs
obj_all=read.table('objectives_all463.txt') # load data for calculating robustness
obj_all=rename(obj_all, "ID"="policy")
vol_index=which(colnames(obj_all) %in% c('LB.Shortage.Volume',"LB.Shortage.Volume.Policy", "Max.Annual.LB.Shortage"))
obj_all[,vol_index]=obj_all[,vol_index]/1000 # convert to KAF
obj_all[["Powell.WY.Release"]]=obj_all[["Powell.WY.Release"]]/(10^6) # convert to MAF
### load uncertainty metrics
SOW_500_300_100=readRDS("SOW ensemble 500_300_100.rds") # list of SOW ensembles, for sensitivity analysis of 300 vs 500 ensemble
SOW_id=sort(SOW_500_300_100[[2]]$model) # SOW IDs of the 300 member SOW ensemble
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=pd.DataFrame(r.x)")
py_run_string("x=pd.DataFrame(r.x)", local = F)
py_run_string("x=DataFrame(r.x)", local = F)
py_run_string("import pandas as pd")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("import pandas as pd")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=DataFrame(r.x)", local = F)
py_run_string("x=pdDataFrame(r.x)", local = F)
py_run_string("x=pd.DataFrame(r.x)", local = F)
py_run_string("y=r.y")
py_run_string("peel=prim.Prim(x,y, threshold=.7)")
py_run_string("import numpy as np")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=pd.DataFrame(r.x)", local = F)
py_run_string("y=np.array(r.y)")
py_run_string("peel=prim.Prim(x,y, threshold=.7)")
py_run_string("peel.find_box()")
py_run_string("import pandas as pd")
py_run_string("import numpy as np")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=pd.DataFrame(r.x)")
py_run_string("y=np.array(r.y)")
py_run_string("peel=prim.Prim(x,y, threshold=.7)")
py_run_string("Mead_norm_PRIM=peel.find_box()")
py_run_string("plt.show()")
py_run_string("import matplotlib.pyplot as plt")
py_run_string("import pandas as pd")
py_run_string("import numpy as np")
py_run_string("import matplotlib.pyplot as plt")
py_run_string("from ema_workbench.analysis import (prim, feature_scoring)")
py_run_string("x=pd.DataFrame(r.x)")
py_run_string("y=np.array(r.y)")
py_run_string("peel=prim.Prim(x,y, threshold=.7)")
py_run_string("Mead_norm_PRIM=peel.find_box()")
py_run_string("plt.show()")
library(ggplot2)
library(reshape2)
coverage=runif(10)
id=1:10
coverage=runif(10)
density=runif(10)
id=1:10
mass=runif(10)
mean=density
res_dim=runif(10)
dummy_wide=data.frame(coverage, density, id, mass, mean, res_dim)
dummy_long=melt(dummy_wide, id.vars = "id")
View(dummy_long)
dummy_long=melt(dummy_wide, id.vars = c("id", "coverage", "density"))
View(dummy_long)
ggplot(data=dummy_wide, aes(x=coverage, y=density, color=res_dim))+
geom_point(size=14 )
ggplot(data=dummy_wide, aes(x=coverage, y=density, color=res_dim))+
geom_point(size=13 )+
scale_color_discrete()
res_dim=round(10*runif(10))
dummy_wide=data.frame(coverage, density, id, mass, mean, res_dim)
ggplot(data=dummy_wide, aes(x=coverage, y=density, color=res_dim))+
geom_point(size=13 )+
scale_color_discrete()
View(dummy_long)
View(dummy_wide)
ggplot(data=dummy_wide, aes(x=coverage, y=density, color=res_dim))+
geom_point(size=13 )+
scale_color_continuous()
?scale_color_continuous
library(plotly)
library(plotly)
?ggplotly
library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
source(".Rprofile")
PYTHON_DEPENDENCIES = c('ema_workbench', 'pandas', "numpy", "scipy", "matplotlib", "seaborn", "sklearn", "statsmodels", "pygments")
virtualenv_dir = Sys.getenv('VIRTUALENV_NAME')
python_path = Sys.getenv('PYTHON_PATH')
# Create virtual env and install dependencies
reticulate::virtualenv_create(envname = virtualenv_dir, python = python_path)
Sys.setenv(PYTHON_PATH = 'python3')
# library(prim)
# library(PRIM)
library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
source("G:/My Drive/CU Boulder/Phase 4 Scenario Discovery/R/Interactive dashboards/V1/sdprim wrapper function.R")
source("G:/My Drive/CU Boulder/Phase 4 Scenario Discovery/R/Interactive dashboards/V1/SD function library.R")
library(sdtoolkit)
# CRB-Scenario-Discovery-App is what you are tracking with GitHub
setwd('G:/My Drive/CU Boulder/Phase 4 Scenario Discovery/R/Interactive dashboards/CRB-Scenario-Discovery-App')
filename='ScenarioDiscoveryWebapp.Rmd'
# make errors print in r console
# options(shiny.error=browser)
# stop errors from printing in r console
# options(shiny.error=NULL)
# render to your Viewer. From viewer, can publish to a server like shinyapps.io or open in browser
# rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0"))
# launch app to your web browser
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0", launch.browser=TRUE))
test=SOW_500_300_100[[1]]$SOW
View(test)
SOW_all=SOW_500_300_100[[1]]$SOW
SOW_all=dplyr::select(SOW_all, -matches(c("RolDef.", "median", ".Freq")))
View(SOW_all)
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0", launch.browser=TRUE))
SOW_all=SOW_500_300_100[[1]]$SOW
SOW_all=dplyr::select(SOW_all, -matches(c("RolDef.", "median", ".Freq", "min", "max")))
View(SOW_all)
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0", launch.browser=TRUE))
long.data=long_data
wide.data=wide_data
metric= optimization
to_plot=c(4,1,3,7)
metric_label='order'
preferred_direction='min'
y_axis2=F
labelsize=3
show_legend=F
filter.long=dplyr::filter(long.data, policy %in% to_plot)
filter.wide=dplyr::filter(wide.data, ID %in% to_plot)
filter.metric=dplyr::filter(metric, ID %in% to_plot)
View(filter.long)
# filter for chosen policies
filter.long=dplyr::filter(long.data, policy %in% fct_inorder(to_plot))
# filter for chosen policies
filter.long=long.data[long.data$policy %in% to_plot,]
View(filter.long)
# filter for chosen policies
filter.long=dplyr::filter(long.data, policy %in% to_plot)
filter.wide=dplyr::filter(wide.data, ID %in% to_plot)
filter.metric=dplyr::filter(metric, ID %in% to_plot)
correction=ifelse(preferred_direction == 'min', 1, -1) # to handle metrics that should be minimized and maximizied accordingly in the ranking
decreasing=ifelse(preferred_direction == 'min', F, T) # needed for add_lines in plot function
if(metric_label=="order"){
filter.metric$order=1:nrow(filter.metric) # add a column that simply indicates the order by which user added metrics
filter.metric=left_join(x=data.frame(order=as.integer(to_plot)), y=filter.metric, by="order") # reorder by the order in which user entered them
}
View(filter.metric)
# filter for chosen policies
filter.long=dplyr::filter(long.data, policy %in% to_plot)
filter.wide=dplyr::filter(wide.data, ID %in% to_plot)
filter.metric=dplyr::filter(metric, ID %in% to_plot)
View(filter.long)
View(filter.metric)
correction=ifelse(preferred_direction == 'min', 1, -1) # to handle metrics that should be minimized and maximizied accordingly in the ranking
decreasing=ifelse(preferred_direction == 'min', F, T) # needed for add_lines in plot function
metric_label=="order"
filter.metric$order=1:nrow(filter.metric) # add a column that simply indicates the order by which user added metrics
View(filter.metric)
filter.long=dplyr::filter(long.data, policy %in% to_plot[1])
filter.wide=dplyr::filter(wide.data, ID %in% to_plot[1])
filter.metric=dplyr::filter(metric, ID %in% to_plot[1])
filter.long=dplyr::filter(long.data, policy %in% to_plot[1])
filter.wide=dplyr::filter(wide.data, ID %in% to_plot[1])
filter.metric=dplyr::filter(metric, ID %in% to_plot[1])
!is.null(to_plot[2])
if(!is.null(to_plot[2])){
for(i in to_plot[-1]){
add=dplyr::filter(long.data, ID==i)
filter.long=rbind(filter.long, add)
add=dplyr::filter(wide.data, ID==i)
filter.wide=rbind(filter.wide, add)
add=dplyr::filter(metric, ID==i)
filter.metric=rbind(filter.metric, add)
}
}
View(filter.long)
View(filter.metric)
filter.long=dplyr::filter(long.data, policy %in% to_plot[1])
filter.wide=dplyr::filter(wide.data, ID %in% to_plot[1])
filter.metric=dplyr::filter(metric, ID %in% to_plot[1])
if(!is.null(to_plot[2])){
for(i in to_plot[-1]){
add=dplyr::filter(long.data, policy==i)
filter.long=rbind(filter.long, add)
add=dplyr::filter(wide.data, ID==i)
filter.wide=rbind(filter.wide, add)
add=dplyr::filter(metric, ID==i)
filter.metric=rbind(filter.metric, add)
}
}
View(filter.metric)
# get rank, append to data frames
correction=ifelse(preferred_direction == 'min', 1, -1) # to handle metrics that should be minimized and maximizied accordingly in the ranking
decreasing=ifelse(preferred_direction == 'min', F, T) # needed for add_lines in plot function
if(metric_label=="order"){
filter.metric$order=1:nrow(filter.metric) # add a column that simply indicates the order by which user added metrics
filter.metric=left_join(x=data.frame(order=as.integer(to_plot)), y=filter.metric, by="order") # reorder by the order in which user entered them
}
View(filter.metric)
filter.long=dplyr::filter(long.data, policy %in% to_plot[1])
filter.wide=dplyr::filter(wide.data, ID %in% to_plot[1])
filter.metric=dplyr::filter(metric, ID %in% to_plot[1])
if(!is.null(to_plot[2])){
for(i in to_plot[-1]){
add=dplyr::filter(long.data, policy==i)
filter.long=rbind(filter.long, add)
add=dplyr::filter(wide.data, ID==i)
filter.wide=rbind(filter.wide, add)
add=dplyr::filter(metric, ID==i)
filter.metric=rbind(filter.metric, add)
}
}
correction=ifelse(preferred_direction == 'min', 1, -1) # to handle metrics that should be minimized and maximizied accordingly in the ranking
decreasing=ifelse(preferred_direction == 'min', F, T) # needed for add_lines in plot function
if(metric_label=="order"){
filter.metric$order=1:nrow(filter.metric) # add a column that simply indicates the order by which user added metrics
# filter.metric=left_join(x=data.frame(order=as.integer(to_plot)), y=filter.metric, by="order") # reorder by the order in which user entered them
}
filter.metric$rank=rank(correction*filter.metric[[metric_label]], ties.method = 'first')
filter.long$rank=rep(filter.metric$rank, each=length(unique(filter.long$Tier)))
filter.wide$rank=filter.metric$rank
View(filter.metric)
View(filter.long)
View(filter.wide)
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0", launch.browser=TRUE))
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0"))
rmarkdown::run(filename, shiny_args = list(port = 3838, host = "0.0.0.0", launch.browser=TRUE))
